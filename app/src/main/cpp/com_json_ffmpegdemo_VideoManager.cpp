/* DO NOT EDIT THIS FILE - it is machine generated */
#include "jni.h"
#include "string.h"
#include "time.h"
/* Header for class com_json_ffmpegdemo_VideoManager */
#include "android/log.h"

#define LOG_TAG "FFMPEG_LOG"
#define LOG_D(...)  __android_log_print(ANDROID_LOG_DEBUG,LOG_TAG,__VA_ARGS__)
#ifdef __cplusplus

extern "C" {
    #include "include/libavcodec/avcodec.h"
    #include "include/libavformat/avformat.h"
    #include "include/libavfilter/avfilter.h"
    #include <libavutil/imgutils.h>
    #include <libswscale/swscale.h>
    #include "android/native_window_jni.h"
    #include <libswresample/swresample.h>
    #endif
    struct info {
        int rate; //帧速率
        char duration[256]; //视频时长
    };
    /**
    * @brief 将一个AVRational类型的分数转换为double类型的浮点数
    * @param r:r为一个AVRational类型的结构体变量，成员num表示分子，成员den表示分母，r的值即为(double)r.num / (double)r.den。用这种方法表示可以最大程度地避免精度的损失
    * @return 如果变量r的分母den为0，则返回0（为了避免除数为0导致程序死掉）;其余情况返回(double)r.num / (double)r.den
    */
    static double r2d(AVRational r) {
        return r.den == 0 ? 0 : (double) r.num / (double) r.den;
    }

    /**
     *  获取视频信息
     */
    JNIEXPORT jobject  JNICALL Java_com_json_ffmpegdemo_VideoManager_getInfo
            (JNIEnv *env, jobject, jstring path) {

        time_t start = time(NULL);
        LOG_D("开始时间：%s", ctime(&start));
        jclass jInfoClass = env->FindClass("com/json/ffmpegdemo/Info"); // 获取类 引用
        jmethodID id = env->GetMethodID(jInfoClass, "<init>", "()V"); //创建构造方法
        jobject jInfo = env->NewObject(jInfoClass, id);
        jfieldID rate = env->GetFieldID(jInfoClass, "rate", "D");
        jfieldID duration = env->GetFieldID(jInfoClass, "duration", "I");
        jfieldID fileName = env->GetFieldID(jInfoClass, "fileName", "Ljava/lang/String;");
        const char *config = avcodec_configuration();
        LOG_D("%s", config);
        //1,注册解封装
        av_register_all();
        //2,获取上下文
        AVFormatContext *formatContext = NULL;
        //3,打开文件
        const char *filePath = env->GetStringUTFChars(path, NULL);
        LOG_D("filePath --->%s", filePath);
        int result = avformat_open_input(&formatContext, filePath, NULL, NULL);
        if (result != 0) {
            return env->NewStringUTF("文件打开失败");
        }
        avformat_find_stream_info(formatContext, NULL);
        LOG_D("INFO --->%s", formatContext->url);
        int tns, thh, tmm, tss;
        tns = static_cast<int>((formatContext->duration) / AV_TIME_BASE);
        thh = tns / 3600;
        tmm = (tns % 3600) / 60;
        tss = (tns % 60);
        LOG_D("媒体文件总时长：%d时%d分%d秒", thh, tmm, tss);

        //设置url
        env->SetObjectField(jInfo, fileName, env->NewStringUTF(formatContext->url));
        //设置时长
        env->SetIntField(jInfo, duration, tns);

        int videoStream = -1;
        int audioStream = -1;

        //获取视频流和音频流
    //    LOG_D("nb_streams --->%d",  formatContext -> nb_streams);
    //    LOG_D("AVMEDIA_TYPE_VIDEO --->%d",  AVMEDIA_TYPE_VIDEO);
    //    LOG_D("AVMEDIA_TYPE_AUDIO --->%d",  AVMEDIA_TYPE_AUDIO);
        for (int i = 0; i < formatContext->nb_streams; ++i) {
            AVStream *as = formatContext->streams[i];
            LOG_D("test --->%d", as->codecpar->codec_type);
            if (AVMEDIA_TYPE_VIDEO == as->codecpar->codec_type) {
                LOG_D("111111111");
                videoStream = i;
                LOG_D("视频帧率 --->%lffps", r2d(as->avg_frame_rate));
                //设置帧速率
                env->SetDoubleField(jInfo, rate, r2d(as->avg_frame_rate));
            } else if (AVMEDIA_TYPE_AUDIO == as->codecpar->codec_type) {
                audioStream = i;
                LOG_D("2222222");
            }
        }

        if (videoStream == -1) {
            LOG_D("找不到视频流");
        }
        if (audioStream == -1) {
            LOG_D("找不到音频流");
        }
        if (formatContext) {
            avformat_close_input(&formatContext);
        }

        time_t end = time(NULL);
        LOG_D("结束时间：%s", ctime(&end));
        LOG_D("audioStream --->%d", audioStream);
        LOG_D("videoStream --->%d", videoStream);
        return jInfo;
    }


    JNIEXPORT void JNICALL
    Java_com_json_ffmpegdemo_VideoManager_play(JNIEnv *env, jobject  instance, jobject surface, jstring jpath) {
        av_register_all();
        AVFormatContext *afx = NULL;
        const char *path = env->GetStringUTFChars(jpath, 0);
        int openResult = avformat_open_input(&afx, path, NULL, NULL);
        if (openResult != 0) {
            return;
        }
        bool  isVideo = true;
        if(isVideo){
            int av_stream_result_video = -1;
            for(int i=0; i< afx->nb_streams; i++)
                if(afx->streams[i]->codecpar->codec_type==AVMEDIA_TYPE_VIDEO){
                    av_stream_result_video=i;
                    break;
                }
            LOG_D("av_stream_result_video %d", av_stream_result_video);
            if (av_stream_result_video == -1) {
                //处理视频
                LOG_D("未获取视频流");
                return;
            }


//        avcodec_register_all();
            //获取解码器

            AVCodecParameters *video_codec_params = afx->streams[av_stream_result_video]->codecpar;
            AVCodec *video_codec = avcodec_find_decoder(video_codec_params->codec_id);

            AVCodecContext *pCodecCtx = avcodec_alloc_context3(NULL);
            avcodec_parameters_to_context(pCodecCtx, video_codec_params);
//        LOG_D("解码像素 %d",acc -> pix_fmt);
//        if(AV_PIX_FMT_NONE == acc ->pix_fmt){
//            LOG_D("像素格式不支持");
//            return;
//        }

            int codecResult = avcodec_open2(pCodecCtx, video_codec, NULL);
            if (codecResult < 0) {
                LOG_D("解码失败222");
                return;
            }
            LOG_D("11111111111111");
            pCodecCtx -> pix_fmt = AV_PIX_FMT_YUV420P;
            AVPacket *av_packet = (AVPacket *)av_malloc(sizeof(AVPacket));
            struct SwsContext *img_convert_ctx = sws_getContext(pCodecCtx->width, pCodecCtx->height,pCodecCtx -> pix_fmt ,
                                                                pCodecCtx->width, pCodecCtx->height, AV_PIX_FMT_YUV420P, SWS_BICUBIC, NULL, NULL, NULL);
            LOG_D("222222222");
            if(img_convert_ctx==NULL){
                LOG_D("swsContext==NULL");
                return;
            }
            ANativeWindow *window = ANativeWindow_fromSurface(env, surface);
            //  av_init_packet(av_packet);

            //转成YUV420P
            AVFrame *av_frame = av_frame_alloc();
            AVFrame *yuv_frame = av_frame_alloc();
            int num = av_image_get_buffer_size(AV_PIX_FMT_YUV420P, pCodecCtx->width, pCodecCtx->height, 1);
            uint8_t *out_buffer = (uint8_t *) av_malloc((size_t) num);
            LOG_D("2222222222 %d", num);
            //初始化缓冲区
            av_image_fill_arrays(yuv_frame->data, yuv_frame->linesize, out_buffer, AV_PIX_FMT_YUV420P,
                                 pCodecCtx->width, pCodecCtx->height, 1);
            LOG_D("33333333 %d", pCodecCtx -> width);
            LOG_D("44444 %d", pCodecCtx -> height);
            AVPixelFormat format = pCodecCtx -> pix_fmt;
            LOG_D("555 %d", format);
//        SwsContext *sws_ctx = sws_getContext(acc -> width ,
//                acc ->height ,
//                acc -> pix_fmt,
//                acc ->width,
//                acc -> height,
//                AV_PIX_FMT_RGBA,
//                SWS_BICUBIC,NULL,NULL,NULL);
            // 由于解码出来的帧格式不是RGBA的,在渲染之前需要进行格式转换
//        SwsContext *sws_ctx = sws_getContext(acc->width,
//                                             acc->height,
//                                             acc->pix_fmt,
//                                             acc->width,
//                                             acc->height,
//                                             AV_PIX_FMT_RGBA,
//                                             SWS_BICUBIC,
//                                             NULL,
//                                             NULL,
//                                             NULL);
            LOG_D("44444444444 %d", num);
            //    LOG_D("55555555555 %d", num);

            ANativeWindow_Buffer window_buffer;
            int video_width = pCodecCtx->width;
            int video_height = pCodecCtx->height;
            //
            ANativeWindow_setBuffersGeometry(window, video_width, video_height, WINDOW_FORMAT_RGBA_8888);
            while (av_read_frame(afx, av_packet) == 0) {
                if (av_packet->stream_index == av_stream_result_video) {
                    int ret = avcodec_send_packet(pCodecCtx, av_packet);
                    if (ret == 0) {
                        int receiveFrameState = avcodec_receive_frame(pCodecCtx, av_frame);
                        if (receiveFrameState == 0) {
                            ANativeWindow_lock(window, &window_buffer, 0);
                            // 格式转换
                            sws_scale(img_convert_ctx, (const uint8_t *const *) av_frame->data, av_frame->linesize,
                                      0,
                                      av_frame->height, yuv_frame->data, yuv_frame->linesize);
                            // 获取stride
                            uint8_t *dst = static_cast<uint8_t *>(window_buffer.bits);
                            int dstStride = window_buffer.stride * 4;
                            uint8_t *src = yuv_frame->data[0];
                            int srcStride = yuv_frame->linesize[0];
                            // 由于window的stride和帧的stride不同,因此需要逐行复制
                            int h;
                            for (h = 0; h < video_height; h++) {
                                memcpy(dst + h * dstStride, src + h * srcStride,
                                       static_cast<size_t>(srcStride));
                            }
                            ANativeWindow_unlockAndPost(window);
                        }
                    }
                    av_packet_unref(av_packet);
                }
            }

        } else {
            int av_stream_result_audio = -1;
            for(int i=0; i< afx->nb_streams; i++)
                if(afx->streams[i]->codecpar->codec_type==AVMEDIA_TYPE_AUDIO){
                    av_stream_result_audio=i;
                    break;
                }
            AVCodecParameters *video_codec_params = afx->streams[av_stream_result_audio]->codecpar;
            AVCodec *video_codec = avcodec_find_decoder(video_codec_params->codec_id);
            AVCodecContext *pCodecCtx = avcodec_alloc_context3(NULL);
            if (avcodec_open2(pCodecCtx, video_codec, NULL)<0) {
            }
            AVPacket *packet = (AVPacket *)av_malloc(sizeof(AVPacket));
            AVFrame *frame = av_frame_alloc();
            SwrContext *swrContext = swr_alloc();
            uint8_t *out_buffer = (uint8_t *) av_malloc(44100 * 2);
            uint64_t  out_ch_layout=AV_CH_LAYOUT_STEREO;
            enum AVSampleFormat out_formart=AV_SAMPLE_FMT_S16;
            int out_sample_rate = pCodecCtx->sample_rate;
            swr_alloc_set_opts(swrContext, out_ch_layout, out_formart, out_sample_rate,
                               pCodecCtx->channel_layout, pCodecCtx->sample_fmt, pCodecCtx->sample_rate, 0,
                               NULL);
            swr_init(swrContext);
            //    获取通道数  2
            int out_channer_nb = av_get_channel_layout_nb_channels(AV_CH_LAYOUT_STEREO);
//    反射得到Class类型
            jclass david_player = env->GetObjectClass(instance);
            if(david_player == NULL){
                LOG_D("播放器空");
            }

//    反射得到createAudio方法
            jmethodID createAudio = env->GetMethodID(david_player, "createTrack", "(II)V");
//    反射调用createAudio
            env->CallVoidMethod(instance, createAudio, 44100, out_channer_nb);
            jmethodID audio_write = env->GetMethodID(david_player, "playTrack", "([BI)V");
            int got_frame;
            LOG_D("播放开始");
            while (av_read_frame(afx, packet) >= 0) {
                if (packet->stream_index == av_stream_result_audio) {
//            解码  mp3   编码格式frame----pcm   frame
                    int ret = avcodec_send_packet(pCodecCtx, packet);
                   // avcodec_decode_audio4(pCodecCtx, frame, &got_frame, packet);
                    LOG_D("播放开始 %d",ret);
                    if (ret == 0) {
                        int receiveFrameState = avcodec_receive_frame(pCodecCtx, frame);
                        if(receiveFrameState == 0){
                            LOG_D("解码 %d",receiveFrameState);
                            swr_convert(swrContext, &out_buffer, 44100 * 2, (const uint8_t **) frame->data, frame->nb_samples);
//                缓冲区的大小
                            int size = av_samples_get_buffer_size(NULL, out_channer_nb, frame->nb_samples,
                                                                  AV_SAMPLE_FMT_S16, 1);
                            jbyteArray audio_sample_array = env->NewByteArray(size);
                            env->SetByteArrayRegion(audio_sample_array, 0, size, (const jbyte *) out_buffer);
                            env->CallVoidMethod(instance, audio_write, audio_sample_array, size);
                            env->DeleteLocalRef(audio_sample_array);
                        }

                    }
                }
            }
            LOG_D("播放结束");
            av_frame_free(&frame);
            swr_free(&swrContext);
            avcodec_close(pCodecCtx);
            avformat_close_input(&afx);
        }


//        ANativeWindow_release(window);
//        av_frame_free(&yuv_frame);
//        av_frame_free(&av_frame);
//        av_packet_free(&av_packet);
//        avcodec_free_context(&pCodecCtx);
//        avformat_close_input(&afx);
//        avformat_free_context(afx);
    }


}
